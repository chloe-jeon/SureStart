{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qPLfdi8UNnpG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "id": "QAt09LlOOkwM",
    "outputId": "44a4cf0f-be1f-425a-8487-8b0a8d04be8e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14115</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10084</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1686</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10382</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1107</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6120</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>952</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7420</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>991</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11924</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1175</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12968</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10652</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1494</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10920</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6120</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>832</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11241</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10791</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13695</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7560</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1029</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallQual  OverallCond  ...  Fireplaces  GarageArea  AboveMedianPrice\n",
       "0      8450            7            5  ...           0         548                 1\n",
       "1      9600            6            8  ...           1         460                 1\n",
       "2     11250            7            5  ...           1         608                 1\n",
       "3      9550            7            5  ...           1         642                 0\n",
       "4     14260            8            5  ...           1         836                 1\n",
       "5     14115            5            5  ...           0         480                 0\n",
       "6     10084            8            5  ...           1         636                 1\n",
       "7     10382            7            6  ...           2         484                 1\n",
       "8      6120            7            5  ...           2         468                 0\n",
       "9      7420            5            6  ...           2         205                 0\n",
       "10    11200            5            5  ...           0         384                 0\n",
       "11    11924            9            5  ...           2         736                 1\n",
       "12    12968            5            6  ...           0         352                 0\n",
       "13    10652            7            5  ...           1         840                 1\n",
       "14    10920            6            5  ...           1         352                 0\n",
       "15     6120            7            8  ...           0         576                 0\n",
       "16    11241            6            7  ...           1         480                 0\n",
       "17    10791            4            5  ...           0         516                 0\n",
       "18    13695            5            5  ...           0         576                 0\n",
       "19     7560            5            6  ...           0         294                 0\n",
       "\n",
       "[20 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('housepricedata.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1Jgf8tBOrcS",
    "outputId": "49c65e01-cfef-45a1-aab8-d005fffe1c61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8450,     7,     5,   856,     2,     1,     3,     8,     0,\n",
       "          548,     1],\n",
       "       [ 9600,     6,     8,  1262,     2,     0,     3,     6,     1,\n",
       "          460,     1],\n",
       "       [11250,     7,     5,   920,     2,     1,     3,     6,     1,\n",
       "          608,     1],\n",
       "       [ 9550,     7,     5,   756,     1,     0,     3,     7,     1,\n",
       "          642,     0],\n",
       "       [14260,     8,     5,  1145,     2,     1,     4,     9,     1,\n",
       "          836,     1],\n",
       "       [14115,     5,     5,   796,     1,     1,     1,     5,     0,\n",
       "          480,     0],\n",
       "       [10084,     8,     5,  1686,     2,     0,     3,     7,     1,\n",
       "          636,     1],\n",
       "       [10382,     7,     6,  1107,     2,     1,     3,     7,     2,\n",
       "          484,     1],\n",
       "       [ 6120,     7,     5,   952,     2,     0,     2,     8,     2,\n",
       "          468,     0],\n",
       "       [ 7420,     5,     6,   991,     1,     0,     2,     5,     2,\n",
       "          205,     0],\n",
       "       [11200,     5,     5,  1040,     1,     0,     3,     5,     0,\n",
       "          384,     0],\n",
       "       [11924,     9,     5,  1175,     3,     0,     4,    11,     2,\n",
       "          736,     1],\n",
       "       [12968,     5,     6,   912,     1,     0,     2,     4,     0,\n",
       "          352,     0],\n",
       "       [10652,     7,     5,  1494,     2,     0,     3,     7,     1,\n",
       "          840,     1],\n",
       "       [10920,     6,     5,  1253,     1,     1,     2,     5,     1,\n",
       "          352,     0],\n",
       "       [ 6120,     7,     8,   832,     1,     0,     2,     5,     0,\n",
       "          576,     0],\n",
       "       [11241,     6,     7,  1004,     1,     0,     2,     5,     1,\n",
       "          480,     0],\n",
       "       [10791,     4,     5,     0,     2,     0,     2,     6,     0,\n",
       "          516,     0],\n",
       "       [13695,     5,     5,  1114,     1,     1,     3,     6,     0,\n",
       "          576,     0],\n",
       "       [ 7560,     5,     6,  1029,     1,     0,     3,     6,     0,\n",
       "          294,     0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values\n",
    "dataset[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awniE2hnOx3F",
    "outputId": "7cfb4b14-b1f1-47e4-a2df-d64b4776d267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8450,     7,     5,   856,     2,     1,     3,     8,     0,\n",
       "          548],\n",
       "       [ 9600,     6,     8,  1262,     2,     0,     3,     6,     1,\n",
       "          460],\n",
       "       [11250,     7,     5,   920,     2,     1,     3,     6,     1,\n",
       "          608],\n",
       "       [ 9550,     7,     5,   756,     1,     0,     3,     7,     1,\n",
       "          642],\n",
       "       [14260,     8,     5,  1145,     2,     1,     4,     9,     1,\n",
       "          836],\n",
       "       [14115,     5,     5,   796,     1,     1,     1,     5,     0,\n",
       "          480],\n",
       "       [10084,     8,     5,  1686,     2,     0,     3,     7,     1,\n",
       "          636],\n",
       "       [10382,     7,     6,  1107,     2,     1,     3,     7,     2,\n",
       "          484],\n",
       "       [ 6120,     7,     5,   952,     2,     0,     2,     8,     2,\n",
       "          468],\n",
       "       [ 7420,     5,     6,   991,     1,     0,     2,     5,     2,\n",
       "          205],\n",
       "       [11200,     5,     5,  1040,     1,     0,     3,     5,     0,\n",
       "          384],\n",
       "       [11924,     9,     5,  1175,     3,     0,     4,    11,     2,\n",
       "          736],\n",
       "       [12968,     5,     6,   912,     1,     0,     2,     4,     0,\n",
       "          352],\n",
       "       [10652,     7,     5,  1494,     2,     0,     3,     7,     1,\n",
       "          840],\n",
       "       [10920,     6,     5,  1253,     1,     1,     2,     5,     1,\n",
       "          352],\n",
       "       [ 6120,     7,     8,   832,     1,     0,     2,     5,     0,\n",
       "          576],\n",
       "       [11241,     6,     7,  1004,     1,     0,     2,     5,     1,\n",
       "          480],\n",
       "       [10791,     4,     5,     0,     2,     0,     2,     6,     0,\n",
       "          516],\n",
       "       [13695,     5,     5,  1114,     1,     1,     3,     6,     0,\n",
       "          576],\n",
       "       [ 7560,     5,     6,  1029,     1,     0,     3,     6,     0,\n",
       "          294]])"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dataset[:,0:10]\n",
    "x[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPvdKagdPeMM",
    "outputId": "d5c4f6df-2337-495e-e55c-8940fc795384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= dataset[:,10]\n",
    "y[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_gjK6R2PkY1",
    "outputId": "ae6660ba-5dd0-4573-8a68-c5e70911c134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0334198 , 0.66666667, 0.5       , 0.1400982 , 0.66666667,\n",
       "        0.5       , 0.375     , 0.5       , 0.        , 0.3864598 ],\n",
       "       [0.03879502, 0.55555556, 0.875     , 0.20654664, 0.66666667,\n",
       "        0.        , 0.375     , 0.33333333, 0.33333333, 0.32440056],\n",
       "       [0.04650728, 0.66666667, 0.5       , 0.15057283, 0.66666667,\n",
       "        0.5       , 0.375     , 0.33333333, 0.33333333, 0.42877292],\n",
       "       [0.03856131, 0.66666667, 0.5       , 0.12373159, 0.33333333,\n",
       "        0.        , 0.375     , 0.41666667, 0.33333333, 0.45275035],\n",
       "       [0.06057632, 0.77777778, 0.5       , 0.18739771, 0.66666667,\n",
       "        0.5       , 0.5       , 0.58333333, 0.33333333, 0.58956276],\n",
       "       [0.05989857, 0.44444444, 0.5       , 0.13027823, 0.33333333,\n",
       "        0.5       , 0.125     , 0.25      , 0.        , 0.33850494],\n",
       "       [0.04105728, 0.77777778, 0.5       , 0.27594108, 0.66666667,\n",
       "        0.        , 0.375     , 0.41666667, 0.33333333, 0.44851904],\n",
       "       [0.04245016, 0.66666667, 0.625     , 0.1811784 , 0.66666667,\n",
       "        0.5       , 0.375     , 0.41666667, 0.66666667, 0.34132581],\n",
       "       [0.02252915, 0.66666667, 0.5       , 0.15581015, 0.66666667,\n",
       "        0.        , 0.25      , 0.5       , 0.66666667, 0.33004231],\n",
       "       [0.02860548, 0.44444444, 0.625     , 0.16219313, 0.33333333,\n",
       "        0.        , 0.25      , 0.25      , 0.66666667, 0.14456982],\n",
       "       [0.04627357, 0.44444444, 0.5       , 0.17021277, 0.33333333,\n",
       "        0.        , 0.375     , 0.25      , 0.        , 0.27080395],\n",
       "       [0.04965762, 0.88888889, 0.5       , 0.19230769, 1.        ,\n",
       "        0.        , 0.5       , 0.75      , 0.66666667, 0.5190409 ],\n",
       "       [0.05453738, 0.44444444, 0.625     , 0.1492635 , 0.33333333,\n",
       "        0.        , 0.25      , 0.16666667, 0.        , 0.24823695],\n",
       "       [0.04371217, 0.66666667, 0.5       , 0.24451718, 0.66666667,\n",
       "        0.        , 0.375     , 0.41666667, 0.33333333, 0.59238364],\n",
       "       [0.04496483, 0.55555556, 0.5       , 0.20507365, 0.33333333,\n",
       "        0.5       , 0.25      , 0.25      , 0.33333333, 0.24823695],\n",
       "       [0.02252915, 0.66666667, 0.875     , 0.13617021, 0.33333333,\n",
       "        0.        , 0.25      , 0.25      , 0.        , 0.40620592],\n",
       "       [0.04646521, 0.55555556, 0.75      , 0.16432079, 0.33333333,\n",
       "        0.        , 0.25      , 0.25      , 0.33333333, 0.33850494],\n",
       "       [0.04436187, 0.33333333, 0.5       , 0.        , 0.66666667,\n",
       "        0.        , 0.25      , 0.33333333, 0.        , 0.36389281],\n",
       "       [0.05793545, 0.44444444, 0.5       , 0.18232406, 0.33333333,\n",
       "        0.5       , 0.375     , 0.33333333, 0.        , 0.40620592],\n",
       "       [0.02925986, 0.44444444, 0.625     , 0.16841244, 0.33333333,\n",
       "        0.        , 0.375     , 0.33333333, 0.        , 0.20733427]])"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scale = min_max_scaler.fit_transform(x)\n",
    "x_scale[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3EwPP_YYPyng"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_vt, y_train, y_vt = train_test_split(x_scale, y, test_size = 0.3)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_vt, y_vt, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "731PgiifQOxS",
    "outputId": "17e60487-10ea-4bc9-81ba-407ba998a5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 10) (219, 10) (219, 10) (1022,) (219,) (219,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_val.shape, x_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ReB0JlnQYqf",
    "outputId": "8843a75a-6704-4d84-f641-cda08ac4ea73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 12s 16ms/step - loss: 0.6882 - accuracy: 0.4921 - val_loss: 0.6796 - val_accuracy: 0.5571\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.5212 - val_loss: 0.6735 - val_accuracy: 0.6027\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.5537 - val_loss: 0.6682 - val_accuracy: 0.6804\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.6665 - val_loss: 0.6630 - val_accuracy: 0.7580\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.7662 - val_loss: 0.6574 - val_accuracy: 0.7717\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.8053 - val_loss: 0.6519 - val_accuracy: 0.7717\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.8252 - val_loss: 0.6461 - val_accuracy: 0.7808\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.8219 - val_loss: 0.6406 - val_accuracy: 0.8082\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.8321 - val_loss: 0.6344 - val_accuracy: 0.8128\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.8356 - val_loss: 0.6282 - val_accuracy: 0.8128\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6256 - accuracy: 0.8452 - val_loss: 0.6216 - val_accuracy: 0.8128\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.8549 - val_loss: 0.6147 - val_accuracy: 0.8128\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.8481 - val_loss: 0.6080 - val_accuracy: 0.8174\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.8480 - val_loss: 0.6011 - val_accuracy: 0.8447\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.8539 - val_loss: 0.5933 - val_accuracy: 0.8402\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.8568 - val_loss: 0.5856 - val_accuracy: 0.8539\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.8214 - val_loss: 0.5773 - val_accuracy: 0.8539\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.8517 - val_loss: 0.5696 - val_accuracy: 0.8584\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.8591 - val_loss: 0.5609 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.8587 - val_loss: 0.5527 - val_accuracy: 0.8630\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8677 - val_loss: 0.5430 - val_accuracy: 0.8630\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.8521 - val_loss: 0.5342 - val_accuracy: 0.8630\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.8780 - val_loss: 0.5247 - val_accuracy: 0.8584\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.8687 - val_loss: 0.5161 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8746 - val_loss: 0.5067 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.8860 - val_loss: 0.4974 - val_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8743 - val_loss: 0.4876 - val_accuracy: 0.8630\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8725 - val_loss: 0.4792 - val_accuracy: 0.8630\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8746 - val_loss: 0.4703 - val_accuracy: 0.8630\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8646 - val_loss: 0.4616 - val_accuracy: 0.8630\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8687 - val_loss: 0.4530 - val_accuracy: 0.8630\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8910 - val_loss: 0.4462 - val_accuracy: 0.8676\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8722 - val_loss: 0.4383 - val_accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8609 - val_loss: 0.4284 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8828 - val_loss: 0.4223 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8829 - val_loss: 0.4154 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8924 - val_loss: 0.4082 - val_accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8674 - val_loss: 0.4010 - val_accuracy: 0.8676\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8731 - val_loss: 0.3958 - val_accuracy: 0.8630\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8805 - val_loss: 0.3894 - val_accuracy: 0.8676\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8801 - val_loss: 0.3842 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8798 - val_loss: 0.3793 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8822 - val_loss: 0.3742 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8647 - val_loss: 0.3695 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8750 - val_loss: 0.3646 - val_accuracy: 0.8676\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8836 - val_loss: 0.3604 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8681 - val_loss: 0.3569 - val_accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8760 - val_loss: 0.3530 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8757 - val_loss: 0.3499 - val_accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8911 - val_loss: 0.3465 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8834 - val_loss: 0.3433 - val_accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8856 - val_loss: 0.3413 - val_accuracy: 0.8767\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8695 - val_loss: 0.3394 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8710 - val_loss: 0.3353 - val_accuracy: 0.8721\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8813 - val_loss: 0.3328 - val_accuracy: 0.8676\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8800 - val_loss: 0.3305 - val_accuracy: 0.8676\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.8962 - val_loss: 0.3294 - val_accuracy: 0.8813\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.8727 - val_loss: 0.3287 - val_accuracy: 0.8721\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3101 - accuracy: 0.8861 - val_loss: 0.3249 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8915 - val_loss: 0.3236 - val_accuracy: 0.8813\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8692 - val_loss: 0.3215 - val_accuracy: 0.8813\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8918 - val_loss: 0.3205 - val_accuracy: 0.8813\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8909 - val_loss: 0.3195 - val_accuracy: 0.8813\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8696 - val_loss: 0.3165 - val_accuracy: 0.8721\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2866 - accuracy: 0.8827 - val_loss: 0.3152 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.8943 - val_loss: 0.3165 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8901 - val_loss: 0.3136 - val_accuracy: 0.8813\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8887 - val_loss: 0.3115 - val_accuracy: 0.8858\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2881 - accuracy: 0.8828 - val_loss: 0.3111 - val_accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8808 - val_loss: 0.3096 - val_accuracy: 0.8858\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8731 - val_loss: 0.3083 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.8838 - val_loss: 0.3078 - val_accuracy: 0.8858\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8836 - val_loss: 0.3062 - val_accuracy: 0.8813\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8896 - val_loss: 0.3060 - val_accuracy: 0.8858\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.8869 - val_loss: 0.3045 - val_accuracy: 0.8858\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8818 - val_loss: 0.3041 - val_accuracy: 0.8858\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8829 - val_loss: 0.3027 - val_accuracy: 0.8858\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.8827 - val_loss: 0.3024 - val_accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.8949 - val_loss: 0.3036 - val_accuracy: 0.8858\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8924 - val_loss: 0.3003 - val_accuracy: 0.8813\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8682 - val_loss: 0.2998 - val_accuracy: 0.8950\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.8861 - val_loss: 0.2994 - val_accuracy: 0.8950\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8864 - val_loss: 0.2989 - val_accuracy: 0.8950\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.9074 - val_loss: 0.2976 - val_accuracy: 0.8858\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.8879 - val_loss: 0.2970 - val_accuracy: 0.8858\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.8899 - val_loss: 0.2966 - val_accuracy: 0.8950\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8926 - val_loss: 0.2966 - val_accuracy: 0.8950\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.8844 - val_loss: 0.2952 - val_accuracy: 0.8904\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.8915 - val_loss: 0.2950 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8866 - val_loss: 0.2944 - val_accuracy: 0.8950\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.8839 - val_loss: 0.2951 - val_accuracy: 0.8904\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2681 - accuracy: 0.8945 - val_loss: 0.2954 - val_accuracy: 0.8858\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2647 - accuracy: 0.8958 - val_loss: 0.2928 - val_accuracy: 0.8950\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8885 - val_loss: 0.2924 - val_accuracy: 0.8950\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2634 - accuracy: 0.8965 - val_loss: 0.2915 - val_accuracy: 0.8950\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.9011 - val_loss: 0.2911 - val_accuracy: 0.8950\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.8900 - val_loss: 0.2913 - val_accuracy: 0.8950\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.9002 - val_loss: 0.2903 - val_accuracy: 0.8950\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.9023 - val_loss: 0.2896 - val_accuracy: 0.8950\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.9020 - val_loss: 0.2896 - val_accuracy: 0.8858\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential([Dense(32, activation = 'relu', input_shape = (10,)),\n",
    "                    Dense(32, activation = 'relu'),\n",
    "                    Dense(1, activation = 'sigmoid')])\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t54O9leoRAou",
    "outputId": "cde0051b-5147-426c-f34f-2dc2995211af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8675799369812012"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)[1]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HousePricesModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
